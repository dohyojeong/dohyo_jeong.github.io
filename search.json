[
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Publications\n[12] DOHYO JEONG. (2024). Medical Resource Optimization Model Analysis for Vulnerable Areas of Emergency Medical Service Using Spatial Machine Learning: A Case Study on Korea. (During peer reviewing).\n[11] DOHYO JEONG. (2024). The Patterns of COVID-19 Therapeutics Supply and Demand in Texas: A Spatial-Temporal INLA Approach. (During peer reviewing).\n[10] DOHYO JEONG., Kim, D., Mohiuddin, H., Kang, S., & Kim, S. (2023). Regional Disparity in the Educational Impact of COVID-19: A Spatial Difference-in-Difference Approach. Sustainability, 15(16), 12514.\n[9] DOHYO JEONG, Jessi Hanson-DeFusco, and Dohyeong Kim. (2022). Digital Mass Hysteria during Pandemics: A Case Study of Twitter Communication Patterns in the US during COVID-19 Period. (During peer reviewing).\n[8] Odusola, A. O., DOHYO JEONG, Malolan, C., Kim, D., Venkatraman, C., Kola-Korolo, O., … & Nwariaku, F. E. (2023). Spatial and temporal analysis of road traffic crashes and ambulance responses in Lagos state, Nigeria. BMC public health, 23(1), 2273.\n[7] Ogbudebe Chidubem, DOHYO JEONG, OdumeBethrand ….. (2023). Editorial Decision/Comments on “Identifying Hotspots of Tuberculosis in Nigeria using Early Warning Outbreak Recognition System: Retrospective Analysis of Implications for Active Case Finding Interventions. JMIR Public Health and Surveillance, 9 (1), e40311.\n[6] CHANG-JIN KIM, DOHYO JEONG, (2022). Factors Influencing Public Officials Innovative Behavior for Platform Governance. The Journal of Korea Policy Research. Vol.22 No.3: 141-171.\n[5] DOHYO JEONG, Sangho Moon, SUHO BAE. (2019). Factors Affecting the Distribution of National Subsidies in Korean Local Governments: Focusing on Rhodes’ Power-Dependence Model. The Korea Journal of Policy Analysis and Management, Vol.29 No3: 21-53.\n[4] DOHYO JEONG, CHANG-JIN KIM, SUHO BAE. (2019). A Study on Determinants of Tax Attitude: Focusing on Slippery Slope Framework, Public Policy Review, Vol.33 No.3: 43-72.\n[3] CHANG-JIN KIM, DOHYO JEONG, SUNG-WOO HONG. (2019). The Effects of Decentralization Perception on the Recognition of Intergovernmental Relationship: Focusing on Mediating Effect of Dispute Settlement System - Journal of Local Government Studies.Vol.31 No.3: 1-35.\n[2] DOHYO JEONG, YOUNGKYU LEE, SEONGYOUNG JEONG. (2018). An Analysis of the Effect of the Tax Rate on the Financial Efficiency of Local Governments. The Korea Journal of Local Government Studies, Vol.22 No.3: 415-443.\n[1] Dae-yong Hyun, DOHYO JEONG, (2017). Analysis of differences in perception of administrative values among civil servants and general civil servants: Focused on Suwon City Government Officials. Suwon Research Institute. No. 12: 119-141.\n\n\n\n\n\nConference Presentation\n[11] DOHYO JEONG. (2023). Differential Side Effects of COVID-19 Response Policies on the U.S. Labor Market: A Spatial-Temporal Analysis. APPAM (Association for Public Policy Analysis and Management) 2023 Annual Conference. Nov. 2023.\n[10] DOHYO JEONG. (2023). The Patterns of COVID-19 Therapeutics Supply and Demand in Texas: A Spatial-Temporal INLA Approach. APHA (American Public Health Association) 2023 Annual Conference. Nov. 2023.\n[9] DOHYO JEONG. (2023). Regional disparity in the uninsurance rate impact of COVID-19: a spatial machine learning approach. ASPA (American Society for Public Administration) 2023 Annual Conference. 21. March. 2023.\n[8] DOHYO JEONG. (2023). Digital Mass Hysteria? during Pandemics: A Case Study of Twitter Communication Patterns in the US during COVID-19 Period. Conference On Public Process Research. 12. Jan. 2023.\n[7] DOHYO JEONG. (2022). A comparison of the spread trend prediction model according to the government’s COVID-19 response policy change and its influence, 2022 Korean Public Administration International Conference. Korea. 22 June. 2022.\n[6] DOHYO JEONG. (2021). The effect of the government’s vaccination management plan on the change of sentiment toward vaccines, 2021 Global Disastronomy Workshop. Texas. USA. 17 Dec. 2021.\n[5] DOHYO JEONG, Chang-jin Kim. SUHO BAE. (2019). A Study on the Factors Affecting the Taxation Attitude of General Taxpayers. Korean Association for Local Government Studies Winter Conference. Seoul. KOREA. 14 Feb. 2019\n[4] Chang-jin Kim. DOHYO JEONG, SUHO BAE. (2019). The Mediation Effect of Dispute Settlement System in the Perception of Regional Dispersion and Intergovernmental Relations. Korean Association for Local Government Studies Winter Conference. Seoul. KOREA. 14 Feb. 2019.\n[3] DOHYO JEONG, YOUNGKYU LEE, SUHO BAE. (2018) An Analysis of the Effect of the Tax Rate on the Financial Efficiency of Local Governments. Korea Association of Local Administration Summer Joint Conference Chungcheong-do. KOREA. 20 Jul. 2018\n[2] DOHYO JEONG. (2017). The Effects of Tax Recognition on the pros and cons of Welfare Policy. Seoul Association of Public Administration Fall Conference. Seoul. KOREA. 3 Nov. 2017\n[1] Dae-yong Hyun, DOHYO JEONG. (2017). A Study on the Policy Diffusion of Local Government in Korea: focusing on Resident Participation Budget System. Korea Association of Local Administration Summer Joint Conference. Gyeonggi-do. KOREA. 18 Aug. 2017"
  },
  {
    "objectID": "Lab03.html",
    "href": "Lab03.html",
    "title": "EPPS 6323: Lab02 R programming (Exploratory Data Analysis)",
    "section": "",
    "text": "R Programming (EDA)\n\n## Creating a function: regplot\n## Combine the lm, plot and abline functions to create a regression fit plot function\nregplot=function(x,y){\n  fit=lm(y~x)\n  plot(x,y)\n  abline(fit,col=\"red\")\n}\n\n\nattach(ISLR::Carseats)\nregplot(Price,Sales)\n\n\n\n## Allow extra room for additional arguments/specifications\nregplot=function(x,y,...){\n  fit=lm(y~x)\n  plot(x,y,...)\n  abline(fit,col=\"red\")\n}  # \"...\" is called ellipsis, which is designed to take any number of named or unnamed arguments.\nregplot(Price,Sales,xlab=\"Price\",ylab=\"Sales\",col=\"blue\",pch=20)\n\n\n\n\n(Adapted from Stackoverflow examples) (Objectives: Use plotly, reshape packages, interactive visualization)\n\nlibrary(tidyverse)\nlibrary(plotly)\ndata(iris)\nattach(iris)\n# Generate plot on three quantitative variables\niris_plot &lt;- plot_ly(iris,\n                     x = Sepal.Length,\n                     y = Sepal.Width,\n                     z = Petal.Length,\n                     type = \"scatter3d\",\n                     mode = \"markers\",\n                     size = 0.02)\niris_plot\n\n\n\n\n# Regression object\n\npetal_lm &lt;- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width,\n               data = iris)\nlibrary(reshape2)\n\n#load data\n\npetal_lm &lt;- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width,data = iris)\n\n# Setting resolution parameter\ngraph_reso &lt;- 0.05\n\n#Setup Axis\naxis_x &lt;- seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = graph_reso)\naxis_y &lt;- seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = graph_reso)\n\n# Regression surface\n# Rearranging data for plotting\npetal_lm_surface &lt;- expand.grid(Sepal.Length = axis_x,Sepal.Width = axis_y,KEEP.OUT.ATTRS = F)\npetal_lm_surface$Petal.Length &lt;- predict.lm(petal_lm, newdata = petal_lm_surface)\npetal_lm_surface &lt;- acast(petal_lm_surface, Sepal.Width ~ Sepal.Length, value.var = \"Petal.Length\")\nhcolors=c(\"orange\",\"blue\",\"green\")[iris$Species]\niris_plot &lt;- plot_ly(iris,\n                     x = ~Sepal.Length,\n                     y = ~Sepal.Width,\n                     z = ~Petal.Length,\n                     text = Species,\n                     type = \"scatter3d\",\n                     mode = \"markers\",\n                     marker = list(color = hcolors),\n                     size=0.02)\n# Add surface\niris_plot &lt;- add_trace(p = iris_plot,\n                       z = petal_lm_surface,\n                       x = axis_x,\n                       y = axis_y,\n                       type = \"surface\",mode = \"markers\",\n                       marker = list(color = hcolors))\niris_plot\n\n\n\n\n\n\n\nRegression object\n\npetal_lm &lt;- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width, \n               data = iris)\nsummary(petal_lm)\n\n\nCall:\nlm(formula = Petal.Length ~ 0 + Sepal.Length + Sepal.Width, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.70623 -0.51867 -0.08334  0.49844  1.93093 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \nSepal.Length  1.56030    0.04557   34.24   &lt;2e-16 ***\nSepal.Width  -1.74570    0.08709  -20.05   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6869 on 148 degrees of freedom\nMultiple R-squared:  0.973, Adjusted R-squared:  0.9726 \nF-statistic:  2663 on 2 and 148 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lab01.html",
    "href": "Lab01.html",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)\n\n\n\n\n\nlength(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3\n\n\n\n\n\n\nx+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"has_annotations\" \"x\"               \"y\"              \n\nrm(x,y) # Remove objects\nls()\n\n[1] \"has_annotations\"\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!\n\n\n\n\n\n#?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=T) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9974701\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)\n\n\n\n\n\nmean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768\n\n\n\n\n\n\nx=rnorm(100)\ny=rnorm(100)\nplot(x,y)\n\n\n\nplot(x,y, pch=20, col = \"firebrick\") # Scatterplot for two numeric variables by default\n\n\n\nplot(x,y, pch=20, col = \"steelblue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\npng \n  2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  },
  {
    "objectID": "Lab01.html#create-object-using-the-assignment-operator--",
    "href": "Lab01.html#create-object-using-the-assignment-operator--",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)"
  },
  {
    "objectID": "Lab01.html#using-function",
    "href": "Lab01.html#using-function",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "length(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3"
  },
  {
    "objectID": "Lab01.html#using---operators",
    "href": "Lab01.html#using---operators",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"has_annotations\" \"x\"               \"y\"              \n\nrm(x,y) # Remove objects\nls()\n\n[1] \"has_annotations\"\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!"
  },
  {
    "objectID": "Lab01.html#matrix-operations",
    "href": "Lab01.html#matrix-operations",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "#?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=T) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9974701\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)"
  },
  {
    "objectID": "Lab01.html#simple-descriptive-statistics-base",
    "href": "Lab01.html#simple-descriptive-statistics-base",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "mean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768"
  },
  {
    "objectID": "Lab01.html#visualization-using-r-graphics-without-packages",
    "href": "Lab01.html#visualization-using-r-graphics-without-packages",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x=rnorm(100)\ny=rnorm(100)\nplot(x,y)\n\n\n\nplot(x,y, pch=20, col = \"firebrick\") # Scatterplot for two numeric variables by default\n\n\n\nplot(x,y, pch=20, col = \"steelblue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\npng \n  2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  },
  {
    "objectID": "Assignment03.html",
    "href": "Assignment03.html",
    "title": "Assignment03",
    "section": "",
    "text": "# Load necessary packages\nlibrary(haven)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n# Read the TEDS2016 dataset\nTEDS_2016 &lt;- read_stata(\"https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true\")\n\nsummary(TEDS_2016)\n\n    District         Sex             Age           Edu            Arear      \n Min.   : 201   Min.   :1.000   Min.   :1.0   Min.   :1.000   Min.   :1.000  \n 1st Qu.:1401   1st Qu.:1.000   1st Qu.:2.0   1st Qu.:2.000   1st Qu.:1.000  \n Median :6406   Median :1.000   Median :3.0   Median :3.000   Median :3.000  \n Mean   :4661   Mean   :1.486   Mean   :3.3   Mean   :3.334   Mean   :2.744  \n 3rd Qu.:6604   3rd Qu.:2.000   3rd Qu.:5.0   3rd Qu.:5.000   3rd Qu.:4.000  \n Max.   :6806   Max.   :2.000   Max.   :5.0   Max.   :9.000   Max.   :6.000  \n                                                                             \n     Career         Career8          Ethnic          Party      \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   : 1.00  \n 1st Qu.:1.000   1st Qu.:2.000   1st Qu.:1.000   1st Qu.: 5.00  \n Median :2.000   Median :4.000   Median :1.000   Median : 7.00  \n Mean   :2.683   Mean   :3.811   Mean   :1.658   Mean   :13.02  \n 3rd Qu.:4.000   3rd Qu.:5.000   3rd Qu.:2.000   3rd Qu.:25.00  \n Max.   :5.000   Max.   :8.000   Max.   :9.000   Max.   :26.00  \n                                                                \n    PartyID          Tondu           Tondu3           nI2       \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   : 1.00  \n 1st Qu.:2.000   1st Qu.:3.000   1st Qu.:2.000   1st Qu.: 1.00  \n Median :2.000   Median :4.000   Median :2.000   Median : 3.00  \n Mean   :4.522   Mean   :4.127   Mean   :2.667   Mean   :35.13  \n 3rd Qu.:9.000   3rd Qu.:5.000   3rd Qu.:3.000   3rd Qu.:98.00  \n Max.   :9.000   Max.   :9.000   Max.   :9.000   Max.   :98.00  \n                                                                \n    votetsai          green         votetsai_nm      votetsai_all   \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1.0000   Median :0.0000   Median :1.0000   Median :1.0000  \n Mean   :0.6265   Mean   :0.3781   Mean   :0.6265   Mean   :0.5478  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n NA's   :429                       NA's   :429      NA's   :248     \n  Independence     Unification           sq           Taiwanese     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :1.0000   Median :1.0000  \n Mean   :0.2888   Mean   :0.1225   Mean   :0.5172   Mean   :0.6272  \n 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n      edu            female        whitecollar       lowincome    \n Min.   :1.000   Min.   :0.0000   Min.   :0.0000   Min.   :1.000  \n 1st Qu.:2.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:4.000  \n Median :3.000   Median :0.0000   Median :1.0000   Median :5.000  \n Mean   :3.301   Mean   :0.4864   Mean   :0.5373   Mean   :4.343  \n 3rd Qu.:5.000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:5.000  \n Max.   :5.000   Max.   :1.0000   Max.   :1.0000   Max.   :5.000  \n NA's   :10                                                       \n     income         income_nm           age              KMT        \n Min.   : 1.000   Min.   : 1.000   Min.   : 20.00   Min.   :0.0000  \n 1st Qu.: 3.000   1st Qu.: 2.000   1st Qu.: 35.00   1st Qu.:0.0000  \n Median : 5.500   Median : 5.000   Median : 49.00   Median :0.0000  \n Mean   : 5.324   Mean   : 5.281   Mean   : 49.11   Mean   :0.2296  \n 3rd Qu.: 7.000   3rd Qu.: 8.000   3rd Qu.: 61.00   3rd Qu.:0.0000  \n Max.   :10.000   Max.   :10.000   Max.   :100.00   Max.   :1.0000  \n                  NA's   :330                                       \n      DPP              npp             noparty            pfp         \n Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :0.0000   Median :0.00000   Median :0.0000   Median :0.00000  \n Mean   :0.3497   Mean   :0.02544   Mean   :0.3716   Mean   :0.01893  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.00000  \n Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000  \n                                                                      \n     South            north        Minnan_father    Mainland_father \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :1.0000   Median :0.0000  \n Mean   :0.4947   Mean   :0.4799   Mean   :0.7225   Mean   :0.1024  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n   Econ_worse       Inequality      inequality5      econworse5   \n Min.   :0.0000   Min.   :0.0000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:4.000   1st Qu.:3.000  \n Median :1.0000   Median :1.0000   Median :5.000   Median :4.000  \n Mean   :0.5544   Mean   :0.9355   Mean   :4.495   Mean   :3.644  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:5.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :1.0000   Max.   :5.000   Max.   :5.000  \n                                                                  \n Govt_for_public     pubwelf5     Govt_dont_care     highincome    \n Min.   :0.0000   Min.   :1.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:2.000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :3.000   Median :0.0000   Median :1.0000  \n Mean   :0.4249   Mean   :2.877   Mean   :0.4988   Mean   :0.5765  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :5.000   Max.   :1.0000   Max.   :1.0000  \n                                                   NA's   :330     \n    votekmt         votekmt_nm          Blue       Green      No_Party\n Min.   :0.0000   Min.   :0.0000   Min.   :0   Min.   :0   Min.   :0  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0   1st Qu.:0   1st Qu.:0  \n Median :0.0000   Median :0.0000   Median :0   Median :0   Median :0  \n Mean   :0.2053   Mean   :0.2752   Mean   :0   Mean   :0   Mean   :0  \n 3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:0   3rd Qu.:0   3rd Qu.:0  \n Max.   :1.0000   Max.   :1.0000   Max.   :0   Max.   :0   Max.   :0  \n                  NA's   :429                                         \n    voteblue       voteblue_nm       votedpp_1        votekmt_1     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :1.0000   Median :0.0000  \n Mean   :0.2787   Mean   :0.3735   Mean   :0.5256   Mean   :0.2309  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                  NA's   :429      NA's   :187      NA's   :187"
  },
  {
    "objectID": "Assignment03.html#age",
    "href": "Assignment03.html#age",
    "title": "Assignment03",
    "section": "1) Age",
    "text": "1) Age\n\nsummary(lm(TEDS_2016$Age~TEDS_2016$votetsai))\n\n\nCall:\nlm(formula = TEDS_2016$Age ~ TEDS_2016$votetsai)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.4671 -1.2848  0.5329  1.5329  1.7152 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         3.46709    0.06555  52.890   &lt;2e-16 ***\nTEDS_2016$votetsai -0.18228    0.08282  -2.201   0.0279 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.423 on 1259 degrees of freedom\n  (429 observations deleted due to missingness)\nMultiple R-squared:  0.003833,  Adjusted R-squared:  0.003042 \nF-statistic: 4.844 on 1 and 1259 DF,  p-value: 0.02792\n\n## Allow extra room for additional arguments/specifications\nregplot=function(x,y,...){\n  fit=lm(y~x)\n  plot(x,y,...)\n  abline(fit,col=\"red\")\n}  # \"...\" is called ellipsis, which is designed to take any number of named or unnamed arguments.\nregplot(TEDS_2016$Age,TEDS_2016$votetsai, \n        xlab=\"Age\",ylab=\"Votes for Tsai Ing-wen\",col=\"blue\",pch=20)"
  },
  {
    "objectID": "Assignment03.html#education",
    "href": "Assignment03.html#education",
    "title": "Assignment03",
    "section": "2) Education",
    "text": "2) Education\n\nsummary(lm(TEDS_2016$Edu~TEDS_2016$votetsai))\n\n\nCall:\nlm(formula = TEDS_2016$Edu ~ TEDS_2016$votetsai)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.4692 -1.2608 -0.2608  1.5308  5.7392 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         3.46921    0.07053  49.190   &lt;2e-16 ***\nTEDS_2016$votetsai -0.20845    0.08910  -2.339   0.0195 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.531 on 1259 degrees of freedom\n  (429 observations deleted due to missingness)\nMultiple R-squared:  0.004328,  Adjusted R-squared:  0.003537 \nF-statistic: 5.473 on 1 and 1259 DF,  p-value: 0.01947\n\n## Allow extra room for additional arguments/specifications\nregplot=function(x,y,...){\n  fit=lm(y~x)\n  plot(x,y,...)\n  abline(fit,col=\"red\")\n}  # \"...\" is called ellipsis, which is designed to take any number of named or unnamed arguments.\nregplot(TEDS_2016$Edu,TEDS_2016$votetsai, \n        xlab=\"Age\",ylab=\"Votes for Tsai Ing-wen\",col=\"blue\",pch=20)"
  },
  {
    "objectID": "Assignment03.html#income",
    "href": "Assignment03.html#income",
    "title": "Assignment03",
    "section": "3) Income",
    "text": "3) Income\n\nsummary(lm(TEDS_2016$income~TEDS_2016$votetsai))\n\n\nCall:\nlm(formula = TEDS_2016$income ~ TEDS_2016$votetsai)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5329 -2.2304  0.2696  2.4671  4.7696 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          5.5329     0.1291  42.845   &lt;2e-16 ***\nTEDS_2016$votetsai  -0.3025     0.1632  -1.854   0.0639 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.803 on 1259 degrees of freedom\n  (429 observations deleted due to missingness)\nMultiple R-squared:  0.002724,  Adjusted R-squared:  0.001931 \nF-statistic: 3.438 on 1 and 1259 DF,  p-value: 0.06393\n\n## Allow extra room for additional arguments/specifications\nregplot=function(x,y,...){\n  fit=lm(y~x)\n  plot(x,y,...)\n  abline(fit,col=\"red\")\n}  # \"...\" is called ellipsis, which is designed to take any number of named or unnamed arguments.\nregplot(TEDS_2016$income,TEDS_2016$votetsai, \n        xlab=\"Age\",ylab=\"Votes for Tsai Ing-wen\",col=\"blue\",pch=20)"
  },
  {
    "objectID": "Assignment01.html",
    "href": "Assignment01.html",
    "title": "Assignment01",
    "section": "",
    "text": "“Which factors are significant in classifying and predicting government officers’ job satisfaction?”\n“Are there any variations in important factors across different countries?”\n\n\n\n\n\nGiven that this study is grounded in machine learning, we do not have a specific hypothesis. Our primary objective is to identify and compare the significant factors influencing job satisfaction.\n\n\n\n\n\nWe will collect and store data using national survey datasets from each respective country.\n\n\n\n\n\nWe will explore classification models such as decision trees, random forests, and XGBoost. Additionally, we will compare the performance of each model to determine the most suitable approach.\n\n\n\n\n\nOur team comprises Dohyo Jeong (Coordinator), Jinju Suk, and Oswald Chau, who will collaborate closely throughout the project."
  },
  {
    "objectID": "Assignment01.html#starting-with-data-or-research-question",
    "href": "Assignment01.html#starting-with-data-or-research-question",
    "title": "Assignment01",
    "section": "",
    "text": "“Which factors are significant in classifying and predicting government officers’ job satisfaction?”\n“Are there any variations in important factors across different countries?”"
  },
  {
    "objectID": "Assignment01.html#do-you-have-a-hypothesis",
    "href": "Assignment01.html#do-you-have-a-hypothesis",
    "title": "Assignment01",
    "section": "",
    "text": "Given that this study is grounded in machine learning, we do not have a specific hypothesis. Our primary objective is to identify and compare the significant factors influencing job satisfaction."
  },
  {
    "objectID": "Assignment01.html#how-data-can-be-collected-and-stored",
    "href": "Assignment01.html#how-data-can-be-collected-and-stored",
    "title": "Assignment01",
    "section": "",
    "text": "We will collect and store data using national survey datasets from each respective country."
  },
  {
    "objectID": "Assignment01.html#what-methods-could-be-considered",
    "href": "Assignment01.html#what-methods-could-be-considered",
    "title": "Assignment01",
    "section": "",
    "text": "We will explore classification models such as decision trees, random forests, and XGBoost. Additionally, we will compare the performance of each model to determine the most suitable approach."
  },
  {
    "objectID": "Assignment01.html#collaboration-and-team-work",
    "href": "Assignment01.html#collaboration-and-team-work",
    "title": "Assignment01",
    "section": "",
    "text": "Our team comprises Dohyo Jeong (Coordinator), Jinju Suk, and Oswald Chau, who will collaborate closely throughout the project."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Education\n\nPh.D. in Public Policy and Political Economy\nUniversity of Texas at Dallas, USA (Aug. 2020 - )\n\n\nMaster of Science in Social Data Analytics and Research\nUniversity of Texas at Dallas, USA (Aug. 2022 - )\n\n\nMaster of Public Administration\nSungkyunkwan University, Seoul, Korea (Mar. 2017 - Feb. 2019)\nThesis Title: Factor Affecting the Distribution of National Subsidies in Korean Local Governments: Focusing on Rhodes’ Power-Dependence Model (Advisor: Professor SUHO BAE)\n\n\nBachelor of Art in Philosophy & Public Administration (double major)\nSeokyeong University, Seoul, Korea (Mar. 2011 - Feb. 2017)\n\n\n\nTeaching\n\nEPPS 2302. Methods of Quantitative Analysis in the Social and Policy Sciences (Fall, 2023)\n\n\n\nTeaching Assistants\n\nEPPS 7316. Regression and Multivariate Analysis (Instructor: Dr. Patrick Brandt, Spring, 2024)\nEPPS 7316. Regression and Multivariate Analysis (Instructor: Dr. Patrick Brandt, Spring, 2023)\nEPPS 7313. Descriptive and Inferential Statistics (Instructor: Dr. Dohyeong Kim, Fall, 2022)\nPPPE 6321. Economics for Public Policy (nstructor: Dr. Dohyeong Kim, Spring, 2022)\n\n\n\nAwards, Scholarships and Honors\n\nAwarded Government and Political Science Fellowship in University of Texas at Dallas (Spring, 2023)\nNominated for President’s Teaching Excellence Awards in University of Texas at Dallas (Spring, 2023)\nAwards 3rd prize in the treatise contest by the KOREA INSTITUTE OF PUBLIC FINANCE (Sep. 2022)\nAwards for Excellent Records, Sungkyunkwan University (Feb. 2019)\nAwards The 3rd Report for Korea National Tax Administration Policy Proposal Contest, National Tax Service (Nov. 2018)\nAcademic Excellence Scholarship, SUNGKYUNWAN UNIVERSITY (Fall 2018)\nAcademic Excellence Scholarship, SUNGKYUNWAN UNIVERSITY (Spring 2018)\nAcademic Excellence Scholarship, SUNGKYUNWAN UNIVERSITY (Fall 2017)\nAn Excellent-grade Scholarship, SEOKYEONG UNIVERSITY (Fall 2016)\nAn Excellent-grade Scholarship, SEOKYEONG UNIVERSITY (Spring 2016)"
  },
  {
    "objectID": "Assignment02.html",
    "href": "Assignment02.html",
    "title": "Assignment02",
    "section": "",
    "text": "1. Lab\nPlease check the Lab01, and Lab02 part.\n\n\n2. Review Chapters 3\n\n# Load necessary packages\nlibrary(haven)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n# Read the TEDS2016 dataset\nTEDS_2016 &lt;- read_stata(\"https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true\")\n\nsummary(TEDS_2016)\n\n    District         Sex             Age           Edu            Arear      \n Min.   : 201   Min.   :1.000   Min.   :1.0   Min.   :1.000   Min.   :1.000  \n 1st Qu.:1401   1st Qu.:1.000   1st Qu.:2.0   1st Qu.:2.000   1st Qu.:1.000  \n Median :6406   Median :1.000   Median :3.0   Median :3.000   Median :3.000  \n Mean   :4661   Mean   :1.486   Mean   :3.3   Mean   :3.334   Mean   :2.744  \n 3rd Qu.:6604   3rd Qu.:2.000   3rd Qu.:5.0   3rd Qu.:5.000   3rd Qu.:4.000  \n Max.   :6806   Max.   :2.000   Max.   :5.0   Max.   :9.000   Max.   :6.000  \n                                                                             \n     Career         Career8          Ethnic          Party      \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   : 1.00  \n 1st Qu.:1.000   1st Qu.:2.000   1st Qu.:1.000   1st Qu.: 5.00  \n Median :2.000   Median :4.000   Median :1.000   Median : 7.00  \n Mean   :2.683   Mean   :3.811   Mean   :1.658   Mean   :13.02  \n 3rd Qu.:4.000   3rd Qu.:5.000   3rd Qu.:2.000   3rd Qu.:25.00  \n Max.   :5.000   Max.   :8.000   Max.   :9.000   Max.   :26.00  \n                                                                \n    PartyID          Tondu           Tondu3           nI2       \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   : 1.00  \n 1st Qu.:2.000   1st Qu.:3.000   1st Qu.:2.000   1st Qu.: 1.00  \n Median :2.000   Median :4.000   Median :2.000   Median : 3.00  \n Mean   :4.522   Mean   :4.127   Mean   :2.667   Mean   :35.13  \n 3rd Qu.:9.000   3rd Qu.:5.000   3rd Qu.:3.000   3rd Qu.:98.00  \n Max.   :9.000   Max.   :9.000   Max.   :9.000   Max.   :98.00  \n                                                                \n    votetsai          green         votetsai_nm      votetsai_all   \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1.0000   Median :0.0000   Median :1.0000   Median :1.0000  \n Mean   :0.6265   Mean   :0.3781   Mean   :0.6265   Mean   :0.5478  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n NA's   :429                       NA's   :429      NA's   :248     \n  Independence     Unification           sq           Taiwanese     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :1.0000   Median :1.0000  \n Mean   :0.2888   Mean   :0.1225   Mean   :0.5172   Mean   :0.6272  \n 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n      edu            female        whitecollar       lowincome    \n Min.   :1.000   Min.   :0.0000   Min.   :0.0000   Min.   :1.000  \n 1st Qu.:2.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:4.000  \n Median :3.000   Median :0.0000   Median :1.0000   Median :5.000  \n Mean   :3.301   Mean   :0.4864   Mean   :0.5373   Mean   :4.343  \n 3rd Qu.:5.000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:5.000  \n Max.   :5.000   Max.   :1.0000   Max.   :1.0000   Max.   :5.000  \n NA's   :10                                                       \n     income         income_nm           age              KMT        \n Min.   : 1.000   Min.   : 1.000   Min.   : 20.00   Min.   :0.0000  \n 1st Qu.: 3.000   1st Qu.: 2.000   1st Qu.: 35.00   1st Qu.:0.0000  \n Median : 5.500   Median : 5.000   Median : 49.00   Median :0.0000  \n Mean   : 5.324   Mean   : 5.281   Mean   : 49.11   Mean   :0.2296  \n 3rd Qu.: 7.000   3rd Qu.: 8.000   3rd Qu.: 61.00   3rd Qu.:0.0000  \n Max.   :10.000   Max.   :10.000   Max.   :100.00   Max.   :1.0000  \n                  NA's   :330                                       \n      DPP              npp             noparty            pfp         \n Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :0.0000   Median :0.00000   Median :0.0000   Median :0.00000  \n Mean   :0.3497   Mean   :0.02544   Mean   :0.3716   Mean   :0.01893  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.00000  \n Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000  \n                                                                      \n     South            north        Minnan_father    Mainland_father \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :1.0000   Median :0.0000  \n Mean   :0.4947   Mean   :0.4799   Mean   :0.7225   Mean   :0.1024  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n   Econ_worse       Inequality      inequality5      econworse5   \n Min.   :0.0000   Min.   :0.0000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:4.000   1st Qu.:3.000  \n Median :1.0000   Median :1.0000   Median :5.000   Median :4.000  \n Mean   :0.5544   Mean   :0.9355   Mean   :4.495   Mean   :3.644  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:5.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :1.0000   Max.   :5.000   Max.   :5.000  \n                                                                  \n Govt_for_public     pubwelf5     Govt_dont_care     highincome    \n Min.   :0.0000   Min.   :1.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:2.000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :3.000   Median :0.0000   Median :1.0000  \n Mean   :0.4249   Mean   :2.877   Mean   :0.4988   Mean   :0.5765  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :5.000   Max.   :1.0000   Max.   :1.0000  \n                                                   NA's   :330     \n    votekmt         votekmt_nm          Blue       Green      No_Party\n Min.   :0.0000   Min.   :0.0000   Min.   :0   Min.   :0   Min.   :0  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0   1st Qu.:0   1st Qu.:0  \n Median :0.0000   Median :0.0000   Median :0   Median :0   Median :0  \n Mean   :0.2053   Mean   :0.2752   Mean   :0   Mean   :0   Mean   :0  \n 3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:0   3rd Qu.:0   3rd Qu.:0  \n Max.   :1.0000   Max.   :1.0000   Max.   :0   Max.   :0   Max.   :0  \n                  NA's   :429                                         \n    voteblue       voteblue_nm       votedpp_1        votekmt_1     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :1.0000   Median :0.0000  \n Mean   :0.2787   Mean   :0.3735   Mean   :0.5256   Mean   :0.2309  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                  NA's   :429      NA's   :187      NA's   :187     \n\n\n\n\n3. What problems do you encounter when working with the dataset?\n\nCheck for missing values.\nInspect the data types of variables.\nIdentify any outliers or inconsistencies in the data.\nAssess the distribution of variables.\nLook for any unexpected or illogical values.\nExamine variable names and labels for clarity and consistency.\n\n\n\n4. How to deal with missing values?\n\nImpute missing values using techniques such as mean, median, mode, or predictive modeling.\nRemove observations with missing values if they are negligible compared to the total dataset.\nAnalyze patterns of missingness and consider whether they are missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR).\nUse multiple imputation methods if appropriate.\n\n\n\n5. Explore the relationship between Tondu and other variables\n\n# Load necessary packages\nlibrary(ggplot2)\n\n# Filter the data for female = 0 and female = 1\nTEDS_female_0 &lt;- TEDS_2016[TEDS_2016$female == 0, ]\nTEDS_female_1 &lt;- TEDS_2016[TEDS_2016$female == 1, ]\n\n# Create a colorful boxplot\nggplot(TEDS_2016, aes(x = factor(female), y = Tondu, fill = factor(female))) +\n  geom_boxplot() +\n  scale_fill_manual(values = c(\"blue\", \"red\")) +\n  labs(x = \"Female\", y = \"Tondu\", title = \"Boxplot of Tondu by Female\") +\n  theme_minimal()\n\n\n\n\n\n# Load necessary packages\nlibrary(ggplot2)\n\n# Create a frequency table for Tondu by Female\nfrequency_table &lt;- with(TEDS_2016, table(Tondu, female))\n\n# Convert the frequency table to a data frame\nfrequency_df &lt;- as.data.frame(frequency_table)\n\n# Rename the columns for better clarity\ncolnames(frequency_df) &lt;- c(\"Tondu\", \"Female\", \"Frequency\")\n\n# Create a colorful bar graph\nggplot(frequency_df, aes(x = Tondu, y = Frequency, fill = factor(Female))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_manual(values = c(\"blue\", \"red\")) +\n  labs(x = \"Tondu\", y = \"Frequency\", fill = \"Female\") +\n  ggtitle(\"Frequency of Tondu by Female\") +\n  theme_minimal()\n\n\n\n\n\n\n6. How about the ‘votetsai’ variable?\n\n# Load necessary packages\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Create frequency table for votetsai variable\nvotetsai_freq &lt;- table(TEDS_2016$votetsai)\n\n# Convert frequency table to data frame\nvotetsai_df &lt;- as.data.frame(votetsai_freq)\ncolnames(votetsai_df) &lt;- c(\"Vote\", \"Frequency\")\n\n# Bar plot of votetsai variable\nbarplot(votetsai_freq, main = \"Votes for Tsai Ing-wen\",\n        xlab = \"Vote\", ylab = \"Frequency\", col = \"skyblue\")\n\n\n\n# Pie chart of votetsai variable\npie(votetsai_freq, main = \"Votes for Tsai Ing-wen\", \n    labels = votetsai_freq, col = rainbow(length(votetsai_freq)))\n\n\n\n# Table of votetsai variable\nprint(votetsai_df)\n\n  Vote Frequency\n1    0       471\n2    1       790\n\n# Bar graph of votetsai variable with ggplot2\nggplot(votetsai_df, aes(x = Vote, y = Frequency, fill = Vote)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Vote\", y = \"Frequency\", fill = \"Vote\") +\n  ggtitle(\"Votes for Tsai Ing-wen\") +\n  theme_minimal()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dohyo Jeong",
    "section": "",
    "text": "Contact me\n\n[email] dohyo.jeong@utdallas.edu\n[LinkedIn] Dohyo Jeong LinkedIn\nAs a Ph.D. candidate in Public Policy and Political Economy at the University of Texas at Dallas, my research ambitiously tackles the optimization of medical resources. This work, which involves extensive study in Public Health, Public Policy Analysis, Machine Learning, Research Methods, and GIS, is driven by a goal to improve healthcare delivery and efficacy. My particular focus on spatial machine learning and the policy impacts of health crises illustrates a profound commitment to addressing these complex challenges through innovative, data-driven strategies. Additionally, I employ econometrics and Bayesian analysis to assess the causal effects of policy interventions, furthering my research in healthcare optimization.\n\nMore Information\n\nInterests:\n* Policy Analysis\n* Public Health Policy\n* Machine Learning\n* Covering Location Problems / Optimization\n* Geographic Information Science"
  },
  {
    "objectID": "Lab02.html",
    "href": "Lab02.html",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "(Adapted from ISLR Chapter 3 Lab: Introduction to R)\n\n\n\nA=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),] # What does -c() do?\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A) # Dimensions\n\n[1] 4 4\n\n\n\n\n\n\nAuto=read.table(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.data\")\nAuto=read.table(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.data\",header=T,na.strings=\"?\") \nAuto=read.csv(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.csv\") # read csv file\n# Which function reads data faster?\n\n# Try using this simple method\n# time1 = proc.time()\n# Auto=read.csv(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.csv\",header=T,na.strings=\"?\")\n# proc.time()-time1\n\n# Check on data\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,] # select rows\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto) # Notice the difference?\n\n[1] 397   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\"        \n\n\n\n\n\n\nAuto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9\n\n\n\n\n\n\n# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\nhist(mpg)\n\n\n\nhist(mpg,col=2)\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\nplot(horsepower,mpg)\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60 \n\n\n\n\n\n\nptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\nInstalling packages into 'C:/Users/dxj190017/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\npackage 'MASS' successfully unpacked and MD5 sums checked\npackage 'ISLR' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\dxj190017\\AppData\\Local\\Temp\\Rtmp23z9Nq\\downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nWarning: package 'MASS' was built under R version 4.3.2\n\n\nLoading required package: ISLR\n\n\nWarning: package 'ISLR' was built under R version 4.3.2\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375 \n\n\n\n\n\n\n\n\n\nlm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nWarning: package 'car' was built under R version 4.3.2\n\n\nLoading required package: carData\n\n\nWarning: package 'carData' was built under R version 4.3.2\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  &lt; 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: &lt; 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)\n\n\n\n\n\nlm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***\nlstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       22.5328     0.2318  97.197  &lt; 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  &lt; 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  &lt; 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -76.488      5.028  -15.21   &lt;2e-16 ***\nlog(rm)       54.055      2.739   19.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  &lt; 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  &lt; 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  &lt; 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  &lt; 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: &lt; 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1\n\n\n\n\n\n\nsummary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lab02.html#indexing-data-using",
    "href": "Lab02.html#indexing-data-using",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "A=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),] # What does -c() do?\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A) # Dimensions\n\n[1] 4 4"
  },
  {
    "objectID": "Lab02.html#loading-data-from-github-remote",
    "href": "Lab02.html#loading-data-from-github-remote",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "Auto=read.table(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.data\")\nAuto=read.table(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.data\",header=T,na.strings=\"?\") \nAuto=read.csv(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.csv\") # read csv file\n# Which function reads data faster?\n\n# Try using this simple method\n# time1 = proc.time()\n# Auto=read.csv(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.csv\",header=T,na.strings=\"?\")\n# proc.time()-time1\n\n# Check on data\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,] # select rows\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto) # Notice the difference?\n\n[1] 397   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\""
  },
  {
    "objectID": "Lab02.html#load-data-from-islr-website",
    "href": "Lab02.html#load-data-from-islr-website",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "Auto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9"
  },
  {
    "objectID": "Lab02.html#additional-graphical-and-numerical-summaries",
    "href": "Lab02.html#additional-graphical-and-numerical-summaries",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\nhist(mpg)\n\n\n\nhist(mpg,col=2)\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\nplot(horsepower,mpg)\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60"
  },
  {
    "objectID": "Lab02.html#linear-regression",
    "href": "Lab02.html#linear-regression",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "ptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\nInstalling packages into 'C:/Users/dxj190017/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\npackage 'MASS' successfully unpacked and MD5 sums checked\npackage 'ISLR' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\dxj190017\\AppData\\Local\\Temp\\Rtmp23z9Nq\\downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nWarning: package 'MASS' was built under R version 4.3.2\n\n\nLoading required package: ISLR\n\n\nWarning: package 'ISLR' was built under R version 4.3.2\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375"
  },
  {
    "objectID": "Lab02.html#multiple-linear-regression",
    "href": "Lab02.html#multiple-linear-regression",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "lm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nWarning: package 'car' was built under R version 4.3.2\n\n\nLoading required package: carData\n\n\nWarning: package 'carData' was built under R version 4.3.2\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  &lt; 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: &lt; 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)"
  },
  {
    "objectID": "Lab02.html#non-linear-transformations-of-the-predictors",
    "href": "Lab02.html#non-linear-transformations-of-the-predictors",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "lm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***\nlstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       22.5328     0.2318  97.197  &lt; 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  &lt; 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  &lt; 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -76.488      5.028  -15.21   &lt;2e-16 ***\nlog(rm)       54.055      2.739   19.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lab02.html#qualitative-predictors",
    "href": "Lab02.html#qualitative-predictors",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  &lt; 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  &lt; 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  &lt; 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  &lt; 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: &lt; 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1"
  },
  {
    "objectID": "Lab02.html#interaction-terms-including-interaction-and-single-effects",
    "href": "Lab02.html#interaction-terms-including-interaction-and-single-effects",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "summary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "Project\n\n\n4. Medical Resource Optimization Model Analysis for Vulnerable Areas of Emergency Medical Service Using Machine Learning: A Case Study on Korea.\n- Research Assistant, University of Texas at Dallas\n• Traffic accident case data collection and mapping.\n• Demand-supply imbalance analysis for medical resources.\n• Optimization model calculation through machine learning.\n• Policy proposals and reports for optimizing medical resources.\n\n\n3. Identifying Hotspots of Tuberculosis in Nigeria using EWORS: Implications for Active Case Finding and Intervention.\n- Research Assistant, University of Texas at Dallas\n\nCombining and managing Nigerian tuberculosis data\nDisease distribution mapping and pattern analysis\nEWORS system effectiveness analysis and evaluation\nSystem effect mapping and geospatial analysis\n\n\n\n2. Emergency Medical Services (EMS) Policy Implementation Evaluation and Efficiency Analysis in Nigeria\n- Research Assistant, University of Texas at Dallas\n\nNigeria traffic accident information mapping and data management\nAmbulance Reaction Time Patterns and Statistical Analysis\nAnalysis and evaluation of traffic policy effects\n\n\n\n1. Pursuing an Empathic Government Through Convergent Leadership Development Program\n- Research Assistant, SUNGKYUNKWAN UNIVERSITY/NATIONAL RESEARCH FOUNDATION OF KOREA\n 1. Party of support: National Research Foundation of Korea\n\nResponsibilities:\n\n\nDiagnosis and development of problems in interdisciplinary convergence research\n\n\nCompare the concept of ‘Publicity’ in the West and the East, and study the definition of publicity in Korean Public Administration\nCompare the bureaucracy theory of the Oriental administration Philosopher Han Feizi and the bureaucracy theory of Max Weber in the West, and derive various implications for application to modern bureaucracy\n\n\nAnalysis and evaluation of the influence of government trust\nStudy the influence of tax recognition and government trust on the welfare policy attitude\n\n\n\n\n\n\nWork Experience\n\n\n2. Gyeonggi Research Institute, Korea\nResearcher, Economic and Social Research Lab (Jan.2020 - May 2020)\n\nResponsibilities\n\n\nLocal industry geographic distribution data collection and analysis.\nEstablishment and analysis of strategic plans for regional strategic industries.\nIndustry policy evaluation and report.\n\n\n\n1. Sustainable Urban Development Institute (SUDI)\nSungkyunkwan University, Seoul, Korea (Apr. 2019 - Jan. 2020)\nResearcher, the Center for Urban Policy Studies \n\nResponsibilities:\n\n\nDiagnosis of problems of local autonomy and decentralization, and development of improvement measures\nAssessment of local government’s fiscal soundness and efficiency\nPolicy development for sustainable local government and rational creation of finance\nStudy on applicability of flexible taxes, tax competition, evaluation of local fiscal reconciliation system, and allocation of government subsidies\nDatabase city information and utilize that information for city research and policy development data\nResearch and application of statistics package such as STATA, SPSS, AMOS, and SAS"
  }
]